# Job
job.factory.class=org.apache.samza.job.dm.DMJobFactory
job.name=StockPriceAverage
job.default.system=kafka
job.container.count=5
job.debounce.time.ms=5000
# Extra delay
job.delay.time.ms=27

#DM
dm.scheduler.class=org.apache.samza.job.dm.MixedLoadBalanceDM.MixedLoadBalanceScheduler
dm.dispatcher.class=org.apache.samza.job.dm.MixedLoadBalanceDM.MixedLoadBalanceDispatcher
dm.enforcerfactory.StockPriceAverage=org.apache.samza.job.yarn.YarnEnforcerFactory

# Scaling and load balancing switch
job.loadbalance.on=true
job.loadbalance.inputtopic=WordSplitterOutput
#Write the host dm is on
job.loadbalance.localityserver.address=192.168.0.18
job.loadbalance.offsetserver.address=192.168.0.18
#Threshold for delay (ms)
job.loadbalance.delay.instant.threshold=100
job.loadbalance.delay.longterm.threshold=1000

#Time to warmup system
job.loadbalance.warmup.time=65000

#Minimum interval between rebalancing
job.loadbalance.interval=2000

#metrics pulling interval in ms
job.loadbalance.delay.interval=400
#User window = alpha * interval
job.loadbalance.delay.alpha=5
#Our window = beta * interval
job.loadbalance.delay.beta=5

job.locality.on=false

# YARN
yarn.package.path=hdfs://yy04:9000/apps/benchmark-0.0.1-dist.tar.gz
cluster-manager.container.memory.mb = 4000

# Task
app.class=benchmark.StockTask.StockPriceAverage
# task.window.ms=2000

# Use StreamProcessor
job.coordinator.factory = org.apache.samza.zk.FollowerJobCoordinatorFactory
job.coordinator.zk.connect = yy07:2181
task.name.grouper.factory = org.apache.samza.container.grouper.task.GroupByContainerIdsFactory


# Kafka System
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.consumer.zookeeper.connect=yy07:2181/
systems.kafka.producer.bootstrap.servers=yy07:9095,yy08:9096
systems.kafka.default.stream.replication.factor=1
systems.kafka.samza.fetch.threshold.bytes = 100000

# Declare that we want our job's checkpoints to be written to Kafka
#task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
#task.checkpoint.system=kafka

# By default, a checkpoint is written every 60 seconds. You can change this if you like.
#task.commit.ms=1000

# Job Coordinator
job.coordinator.system=kafka
job.coordinator.replication.factor=1


# Metrics
metrics.reporters=snapshot, jmx
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
#metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory
metrics.reporter.snapshot.interval=500
metrics.reporter.snapshot.interval.unit=MILLISECONDS
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory
systems.kafka.streams.metrics.samza.msg.serde=metrics
metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory